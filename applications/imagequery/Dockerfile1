FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04 
# Reference: https://github.com/mozilla/DeepSpeech
# Pitfall: We gave to use the image of 9.0 version, instead of 10.0 version, though the official document says that it is supported with cuda 10.0.
# If you use nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04, "ImportError: libcusolver.so.9.0: cannot open shared object file: No such file or directory"
# would appear. This is essentially just a naming problem, but annoying.
# In addition, when running this container, have to put --runtime=nvidia as parameter. As it also uses GPU.
RUN apt-get update
RUN apt-get install wget unzip python3 python3-pip -y
RUN pip3 install grpcio
RUN pip3 install protobuf
RUN apt-get install curl -y
RUN apt-get install ffmpeg -y
RUN pip3 install deepspeech-gpu

ADD imagequery/c1_speechRecognition/app /container/
ADD imagequery/c1_speechRecognition/data /container/data

# dataset1 
# dataset source: http://festvox.org/cmu_arctic/
RUN wget --progress=bar:force http://festvox.org/cmu_arctic/cmu_arctic/packed/cmu_us_awb_arctic-0.95-release.zip
RUN mv $(find / -name cmu_us_awb_arctic-0.95-release.zip) /container/data/dataset1
RUN chmod 777 /container/data/dataset1/unzipRename.sh
RUN /container/data/dataset1/unzipRename.sh

# dataset2
# reference: https://groups.csail.mit.edu/sls/downloads/flickraudio/index.cgi
RUN wget --progress=bar:force https://groups.csail.mit.edu/sls/downloads/flickraudio/downloads/flickr_audio.tar.gz
RUN mv $(find / -name flickr_audio.tar.gz) /container/data/dataset2
RUN chmod 777 /container/data/dataset2/untarRename.sh 
RUN /container/data/dataset2/untarRename.sh

# dataset3
# download reference: https://www.kaggle.com/general/6604
# dataset refernce: https://www.kaggle.com/rtatman/speech-accent-archive/
# RUN curl 'https://storage.googleapis.com/kaggle-datasets/4114/6391/speech-accent-archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1558923578&Signature=nriiruUcrYCm7Hr4rK3kByDRerT3FTHP%2B1GeS3gkPRnNrdTy06VV31Fgch3UpvWuGCsL8eSKh5xnrWzC3gOP95hL523xyNVRJDcsxJ4L4klwpJoLln9ohmPkNPVfIlSH6AVaRH208Aa%2F5BsLFoMIo3rh3jE0D09nMfA2xvAxuxK5QPXp86ZdRtYMMHfBJ5ah5niNjprEiAOLhgumo7k3TzNIRUZi0zn6L7i8Q9XSRuShWQne8RRiGoMeggXtUFqkTnZDbomeI5vnDwT8K%2FOWnY9o91ncd8muYWFnH5BdXOPnJZaDvfg%2BR7C8uApcxcgAhnUjP9jfZJExUsf%2BSMXPKg%3D%3D' -H 'authority: storage.googleapis.com' -H 'pragma: no-cache' -H 'cache-control: no-cache' -H 'upgrade-insecure-requests: 1' -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36' -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3' -H 'referer: https://www.kaggle.com/' -H 'accept-encoding: gzip, deflate, br' -H 'accept-language: en,zh;q=0.9,zh-CN;q=0.8' --compressed -o speech-accent-archive.zip
RUN curl 'https://storage.googleapis.com/kaggle-datasets/4114/6391/speech-accent-archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559281076&Signature=pKwWz%2BUhPjc5keOB4bY0qxkq9vzFdtqKzIT2DBZVH5xmOeQfcM8Lwo8LCC7%2FTCvSXQpbYrCrJ4YqlhKOk1wVS5rCQsdxTDkLVMIL988wwULrCHq9qW35vM075RQl5Az8YqOD15TLP0SVtUGJtweq30pvS4ohzYNjtlnBuJUXAiDBbX3HOgJizfWfCI6dga%2B2K1ZTNudqZRd3xOQQZrDUJ02swEzntK4z7oxYy4bG%2BSpez73V4oQu9JlSnTVjbHTqARKLRHLdOVeDh3rmVo%2Bf0JOXkZjjvIK%2BDWGVdo50yF%2B1WqFoCTZRWs2bJ6KgY52eHdyb%2B4P1XokUcmYlGXCXcg%3D%3D' -X OPTIONS -H 'Access-Control-Request-Method: GET' -H 'Origin: https://www.kaggle.com' -H 'Referer: https://www.kaggle.com/' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36' -H 'Access-Control-Request-Headers: turbolinks-referrer' --compressed -o speech-accent-archive.zip
RUN mv $(find / -name speech-accent-archive.zip) /container/data/dataset3 
RUN ls /container/data/dataset3
RUN unzip /container/data/dataset3/speech-accent-archive.zip -d /container/data/dataset3 
# /container/data/dataset3 now contains:reading-passage.txt, recordings.zip, speakers_all.csv
RUN unzip /container/data/dataset3/recordings.zip -d /container/data/dataset3/
RUN chmod 777 /container/data/dataset3/rename.sh
RUN /container/data/dataset3/rename.sh

# download pre-trained model
RUN wget --progress=bar:force https://github.com/mozilla/DeepSpeech/releases/download/v0.4.1/deepspeech-0.4.1-models.tar.gz
RUN tar xvfz $(find / -name deepspeech-0.4.1-models.tar.gz)
RUN mv /models /container/models

# /container has: predict.py, data, models
# /container/models has: alphabet.txt, lm.binary, output_graph.pb, output_graph.pbmm. output_graph.rounded.pb, output_graph.rounded.pbmm, trie

ADD grpc/app/container_entry.sh /container/
ADD grpc/app/server.py /container/
ADD grpc/app/model_pb2_grpc.py /container/
ADD grpc/app/model_pb2.py /container/
ADD grpc/app/proxy_pb2_grpc.py /container/
ADD grpc/app/proxy_pb2.py /container/

# RUN python3 /container/predict.py --model /container/models/output_graph.pbmm --alphabet /container/models/alphabet.txt --audio /container/data/dataset1/cmu_us_awb_arctic/wav/1.wav
# CMD ["deepspeech","--model","/container/models/output_graph.pbmm","--alphabet","/container/models/alphabet.txt","--audio","/container/data/dataset1/cmu_us_awb_arctic/wav/1.wav"]
# CMD ["/container/container_entry.sh", "c1", "/container/server.py"]

EXPOSE 8000